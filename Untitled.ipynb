{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import itemgetter\n",
    "import collections\n",
    "from datetime import datetime, date\n",
    "data = \"russian-troll-tweets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "all_data_df = pd.read_csv(data + \"IRAhandle_tweets_1.csv\")\n",
    "for i in range(2, 10):\n",
    "    all_data_df = all_data_df.append(pd.read_csv(data + \"IRAhandle_tweets_{}.csv\".format(i)), ignore_index=True)\n",
    "    \n",
    "# Cleaning data\n",
    "all_data_df = all_data_df.dropna()\n",
    "all_data_df[\"publish_date\"] = pd.to_datetime(all_data_df[\"publish_date\"], format='%m/%d/%Y %H:%M')\n",
    "all_data_df['publish_date'] = all_data_df['publish_date'].apply(lambda datetime: datetime.date())\n",
    "\n",
    "account_categories = all_data_df.account_category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## HELPER FUNCTIONS ##\n",
    "\n",
    "def get_hashtags(df, category):\n",
    "    hashtags = []\n",
    "    for t in df[df.account_category == category].content.values:\n",
    "        m = re.search(\"#.* \", t)\n",
    "        if m is not None:\n",
    "            for hashtag in m.group(0).split(\" \"):\n",
    "                if hashtag and hashtag[0] == \"#\":\n",
    "                    hashtags.append(hashtag)\n",
    "    return hashtags\n",
    "\n",
    "def get_tweets(category, with_hashtags=None, keywords=None, retweets_only=False):\n",
    "    df = all_data_df\n",
    "    if retweets_only:\n",
    "        df = df[df.retweet == 1]\n",
    "    tweets = df[df.account_category == category].content.values\n",
    "    if with_hashtags is None:\n",
    "        return tweets\n",
    "    else:\n",
    "        filtered = [x for x in tweets if [w for w in with_hashtags if w in x]]\n",
    "        if keywords is None:\n",
    "            return filtered\n",
    "        else:\n",
    "            return [x for x in filtered if [w for w in keywords if w in x]]\n",
    "\n",
    "def frequencies(hashtags):\n",
    "    res = {}\n",
    "    for hashtag in hashtags:\n",
    "        res[hashtag] = res.get(hashtag, 0.0) + 1.0\n",
    "    return res\n",
    "\n",
    "# Plot the word cloud of the most commonly used ingredients\n",
    "def word_graph(freqs, title=None):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    plt.title(title)\n",
    "    wc = WordCloud(background_color='white', width=1000, height=500).generate_from_frequencies(freqs)\n",
    "    ax=plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.imsave('wc_ing.png', wc)\n",
    "    b=plt.axis('off')\n",
    "    \n",
    "def hashtag_graph(df, category):\n",
    "    hashtags = get_hashtags(df, category)\n",
    "    freqs = frequencies(hashtags)\n",
    "    word_graph(freqs, title=\"{} most used hashtags\".format(category))\n",
    "    \n",
    "def histogram(df, title=None, category=None, size=(15,7), ax=None):\n",
    "    if category is not None:\n",
    "        df = df[df.account_category == category]\n",
    "    res = df.drop(columns=[x for x in list(all_data_df.columns) if x not in [\"publish_date\", \"content\"]])\n",
    "    res = res.rename(columns={\"content\": \"Amount of Tweets\", \"publish_date\":\"Time\"})\n",
    "    res = res.groupby(\"Time\").count()\n",
    "    ax = res.plot(figsize=size, kind=\"area\", title=title, ax=ax)\n",
    "    return ax.get_legend_handles_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Complete histogram\n",
    "_ = histogram(all_data_df, \"All Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations: The IRA activity is focused between 2015 and 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=4, ncols=2)\n",
    "for (index, cat) in enumerate(account_categories):\n",
    "    ax = axes[int(index/2), index%2]\n",
    "    histogram(all_data_df, cat, cat, (25, 15), ax=ax)\n",
    "    ax.get_legend().remove()\n",
    "\n",
    "handles, labels = axes[0,0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper center')\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hashtag_graph(all_data_df, \"RightTroll\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#MAGA: Make America Great Again\n",
    "#tcot: Top Conservatives On Twitter\n",
    "#PJNET: Patriot Journalist Network\n",
    "\n",
    "Others: #NeverHillary, #ISIS, #WakeUpAmerica, #iceisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_graph(all_data_df, \"LeftTroll\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Immitating real users\n",
    "#NowPlaying was used a lot and often found with '#hiphop', '#RAPStationRadio', '#rap', '#music', '#power1044fm.com', '#HipHop', '#checkitout', '#EDM', '#Rap', '#HouseMusic', '#RnB', '#NewMusic', '#Reggae', '#ListenLive', '#HOuseMusic', '#Pop', '#TheIndieHour'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_graph(all_data_df, \"HashtagGamer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags = [\"#MustBeBanned\"]\n",
    "keywords = [\"Clinton\", \"Hillary\", \"Democrats\", \"Obama\"]\n",
    "tweets = get_tweets(\"HashtagGamer\", with_hashtags=hashtags, keywords=keywords, retweets_only=True)\n",
    "collections.Counter(tweets).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def related(df, hashtag, category=None):\n",
    "    dump = [\"\", \"the\", \"-\", \"of\", \"is\", \"to\", \"a\", \"in\", \"for\", \"and\", \"The\", \"on\", \"you\", \"our\", \"not\", \"&\", \"with\", \\\n",
    "           \"We\", \"are\", \"I\", \"be\", \"with\", \"we\", \"your\", \"To\", \"will\", \"who\", \"In\", \"via\", \"that\", \"In\", \\\n",
    "           \"Is\", \"this\", \"it\", \"by\", \"THE\", \"their\", \"my\", \"1.\", \"2.\", \"all\", \"at\", \"Get\", \"get\", \"up\", \\\n",
    "           \"out\", \"new\", \"some\", \"about\", \"This\", \"have\", \"was\", \"as\", \"from\", \"they\", \"has\", \"his\", \"You\"\\\n",
    "           \"what\", \"he\", \"an\", \"but\", \"You\", \"what\", \"so\", \"if\", \"more\", \"do\", \"like\", \"just\", \"can\", \"how\", \\\n",
    "           \"If\", \"A\", \"or\", \"should\", \"For\", \"no\", \"Of\", 'one', 'With', \"It's\", 'He', \"I'm\", 'want', 'And', 'They', 'when',\\\n",
    "           'It', 'My', 'would', 'US', '4', 'back', 'What', 'us', 'New', 'going', 'Great', 'over', 'time', \"don't\", 'after', \\\n",
    "            'know', 'than', 'think', 'need', 'take', 'On', \"because\", \"me\", \"Who\", '��', '�']\n",
    "    hashtags = []\n",
    "    people = []\n",
    "    words = []\n",
    "\n",
    "    if category is not None:\n",
    "        df = df[df.account_category == category]\n",
    "        \n",
    "    tweets = [x for x in df.content.values if hashtag in x]\n",
    "    for tweet in tweets: \n",
    "        for word in tweet.split(\" \"):\n",
    "            if word and word not in dump:\n",
    "                if word[0] == \"#\":\n",
    "                    hashtags.append(word)\n",
    "                elif word[0] == \"@\":\n",
    "                    people.append(word)\n",
    "                else:\n",
    "                    words.append(word)\n",
    "    \n",
    "    all_ = [frequencies(hashtags), frequencies(people), frequencies(words)]\n",
    "    for counter in all_:\n",
    "        print([a for (a, _) in sorted(counter.items(), key=itemgetter(1), reverse=True)][:30])\n",
    "        print()\n",
    "    return tuple(all_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags, people, words = related(all_data_df, \"#NowPlaying\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
